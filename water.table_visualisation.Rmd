---
title:  |
  ![](images/feuille_logo.png){width="30"}  
  **Water table data visualisation graphs**
author: "Alizée Girard"
date: '`r format(Sys.time(), "%x")`'
output:
  pdf_document:
    latex_engine: xelatex
mainfont: "Helvetica"
header-includes:
    - \usepackage{setspace}\singlespacing
geometry: margin=1in
# spacing: single
---

```{=html}
<!-- Notes :

Raw (calibrated) data
Autres codes :
pdf_document 

<!-- https://bookdown.org/yihui/rmarkdown-cookbook/working-directory.html
Sometimes you may want to use another directory as the working directory. The usual way to change the working directory is setwd(), but please note that setwd() is not persistent in R Markdown (or other types of knitr source documents), which means setwd() only works for the current code chunk, and the working directory will be restored after this code chunk has been evaluated. -->
```

\newpage

```{r, echo = FALSE, message = FALSE}
setwd("~/Documents/Doctorat/_R.&.Stats_PhD")
# Libraries
if (!require("knitr")) install.packages("knitr") # Integrating data from weathercan (ECCC/CCCS), Gouvernement du Canada
if (!require("kableExtra")) install.packages("kableExtra") # Integrating data from weathercan (ECCC/CCCS), Gouvernement du Canada

# import
ll.clean <- readRDS("connectivite/data/clean/ll.clean.RDS")
SNH <- as.vector(c("_odyssey", "_hobo"), mode = "character") # liste des types de SNH avec lesquelles j'ai pris des données; chaque "marque" est traitée de façon différente
for (j in 1:length(ll.clean)) {
  print(j)
  ll.clean.j <- ll.clean[[j]]
  
  # ODYSSEY
  if (grepl(SNH[1], ll.clean.j$metadata[11])) {
    # où trouver no de sonde dans ODYSSEY
    metadata.line <- ll.clean.j$metadata[12] # probe.uid
    numbers <- gregexpr("[0-9]+", metadata.line)
    sonde <- regmatches(metadata.line, numbers)
  } else if (grepl(SNH[2], ll.clean.j$metadata[4])) {
    # où trouver no de sonde dans HOBO
    metadata.line <- ll.clean.j$metadata[5] # probe.uid
    numbers <- gregexpr("[0-9]+", metadata.line)
    sonde <- regmatches(metadata.line, numbers)
  }
  # données à visualiser
  data <- ll.clean[[j]]$data
  if (nrow(data) > 0) {
    hist(data$calibrated.value.mm/10, warn.unused = F, 
         main = paste("Histogram des données de sonde no ", paste(sonde,"\n"))) # en cm
  } 
  # les hauteurs de nappe phréatique calibrées devraient toutes être négatives ou presque !
  # ou alors est-ce que les ODYSSEY donnent en + ?
}
```

## Vérification de la calibration des sondes en fonction de la lecture au bulleur

# QUESTION :

# longueur du fil à bulleur, donc nappe en dessous, doit poser problème non ?

# ODYSSEY calibration nous donne la profondeur ou la distance sol-np ?

```{r, echo = FALSE, message = FALSE}
# créé le 23 déc. pour vérifier données des Odyssey de St-Henri 2024
# TRANSFÉRÉ DANS RMarkdown le 7 janvier 2025 / retravaillé 17 janvier et retransféré (en cours)
setwd("~/Documents/Doctorat/_R.&.Stats_PhD")
# Libraries
if (!require("knitr")) install.packages("knitr") # Integrating data from weathercan (ECCC/CCCS), Gouvernement du Canada
if (!require("kableExtra")) install.packages("kableExtra") # Integrating data from weathercan (ECCC/CCCS), Gouvernement du Canada
## import et ménage ----
SNH <- as.vector(c("_odyssey", "_hobo"), mode = "character") # liste des types de SNH avec lesquelles j'ai pris des données; chaque "marque" est traitée de façon différente
ll.bulleur <- read.csv("connectivite/data/clean/ll.bulleur.csv")
ll.clean <- readRDS("connectivite/data/clean/ll.clean.RDS")

## boucle de vérification au bulleur pour chaque SNH (de ll.clean) ----
# fichiers de consigne de données
water.table.verif <- data.frame()
for (m in 1:length(ll.clean)) {
  ll.clean.m <- ll.clean[[m]]; ll.clean[[m]]
  # extraire # sonde des différentes marques de SNH
  if (grepl(SNH[1], ll.clean.m$metadata[11])) { # ODYSSEY
    # où trouver no de sonde dans ODYSSEY metadata
    metadata.line <- ll.clean.m$metadata[12] # probe.uid
    numbers <- gregexpr("[0-9]+", metadata.line)
    sonde.m <- regmatches(metadata.line, numbers)
    # où trouver la date d'extraction dans ODYSSEY metadata
    date.line <- ll.clean.m$metadata[13] # probe.uid
    date.numbers <- gregexpr("[0-9]+", date.line)
    date.m <- unlist(regmatches(date.line, date.numbers))
  } else if (grepl(SNH[2], ll.clean.m$metadata[4])) { # HOBO
    # où trouver no de sonde dans HOBO metadata
    metadata.line <- ll.clean.m$metadata[5] # probe.uid
    numbers <- gregexpr("[0-9]+", metadata.line)
    sonde.m <- unlist(regmatches(metadata.line, numbers))
    # où trouver la date d'extraction dans HOBO metadata
    date.line <- ll.clean.m$metadata[6]
    date.numbers <- gregexpr("[0-9]+", date.line)
    date.m <- unlist(regmatches(date.line, date.numbers))
  }
  # création du dataframe pour chaque vérification au bulleur pour chaque SNH
  if (nrow(ll.clean[[m]]$data) != 0) { # si le fichier SNH n'est pas vide
    water.table.verif.n <- data.frame()
    ll.bulleur.m <- ll.bulleur[ll.bulleur$probe.uid == sonde.m,] # filtrer ll.bulleur par no de sonde "m"
    for (n in 1:nrow(ll.bulleur.m)) {
      ll.bulleur.m.n <- ll.bulleur.m[n,] # filtrer ll.bulleur (level.logger.calibration.all.csv) par le ligne "n" (vérification n au bulleur)
      ll.clean.m.n <- ll.clean.m$data[ll.clean.m$data$date.time.UTC.0 == # fitlrer les données du fichier SNH par la période (unique) de la ligne n = vérification au bulleur
                                        ll.bulleur.m$bulleur.1.date.time.UTC.0,]
      water.table.verif.n[n, 1:4] <- data.frame("probe.uid" = sonde.m, # créer le dataframe de vérification pour les lignes "n" de la SNH "m"
                                                "file.extraction.date" = date.m,
                                                "probe.measure.cm" = ll.clean.m.n$calibrated.value.mm/10,
                                                "bulleur.mesure.cm" = ll.bulleur.m.n$bulleur.1.cm)
    } 
    water.table.verif[nrow(water.table.verif) + 1:nrow(water.table.verif.n), 1:4] <- water.table.verif.n # inscrire les données dans le dataframe final, à la dernière ligne
  } else if (nrow(ll.clean[[m]]$data) == 0)  {
    water.table.verif[nrow(water.table.verif) + 1, 1:4] <- data.frame("probe.uid" = sonde.m, # si ll.clean[[j]]$data est vide, mettre NA dans le dataframe
                                                                      "file.extraction.date" = date.m,
                                                                      "probe.measure.cm" = NA,
                                                                      "bulleur.mesure.cm" = NA)
    } 
  } 
water.table.verif <- water.table.verif[!duplicated(water.table.verif),]
rownames(water.table.verif) <- NULL

# renommmer les colonnes
water.table.verif %>% 
kbl(booktabs = TRUE, linesep = "", caption = "Vérification de la calibration de sonde en fonction de la mesure du bulleur",
col.names =  c("Identifiant unique (UID) de sonde", "Date d'extraction des données de la SNH", "Mesure de la sonde (heure de lecture au bulleur; cm)", "Bulleur (cm)"),
align = "ccc") %>% 
  kable_styling(latex_options = "HOLD_position", full_width = T) # pour que le titre de section n'arrive pas après le tableau
```

## Aperçu du code de calibration - Sonde Odyssey

```         
# Sondes ODYSSEY
### calcul des termes de la calibration ----
# FORMULES
# RES.NP.calibré = ((DATA.raw.value - b.offset) / a.slope ) - longueur.fil
# si Y = (a * X) + b,
# X = ( Y - b ) / a, puis on enlève la longueur du fil à la mesure de NP
# où 
# y = raw.value aux longueurs 1 et 2 du test de calibration (p. ex. 200 mm et 800 mm ou 1400 mm, pour STH)
# b.offset = y1 - a.slope * x1
# a.slope = ( y2 - y1 ) / ( x2 - x1 ), soit la proportion de changement de y pour chaque changement de x
# a.slope = longueur de fil (mm)
# x2 = longueur fil test #2 (V = "cal.order"), x1 = longueur fil test #1 (V = "cal.order")
# y2 = raw.value à du test #2 (V = "cal.value"), y1 = raw.value à du test #1 (V = "cal.value")
{
  longueur.fil = cal.probe.i$cal.length.cm[cal.probe.i$cal.order==1]*10
  x2 = cal.probe.i$cal.length.cm[cal.probe.i$cal.order==2]*10
  x1 = cal.probe.i$cal.length.cm[cal.probe.i$cal.order==1]*10
  y2 = cal.probe.i$cal.value[cal.probe.i$cal.order==2]
  y1 = cal.probe.i$cal.value[cal.probe.i$cal.order==1]
  a.slope = ( y2 - y1 ) / ( x2 - x1 )
  b.offset = y1 - (a.slope * x1)
}

# changer la colonne calibrated pour les données corrigées
ll.cal.pre.i$calibrated.value.mm = ((ll.cal.pre.i$raw.value.mm - b.offset) / a.slope ) - longueur.fil
colnames(ll.cal.pre.i); head(ll.cal.pre.i)
```

### Aperçu du code de calibration - Sonde HOBO

``` r
#### assembler données du HOBO et données de ECCC/CCCS selon la date et l'heure ----
    # Jutras&Bourgault V2.0, 2024; étape a) Associer par dates et par heures les données mesurées par les sondes de niveau hydrostatique et la pression atmosphérique
    cal.eccc.data <- left_join(ll.cal.pre.i, eccc.data, by = join_by(date.time.UTC.0)) %>% 
      select("scan.id", "date.time.UTC.0","raw.value.kPa_pres.abs", "temperature_dC", "calibrated.value.mm",
             `date.AAAA-MM-JJ` = "date.AAAA-MM-JJ.x", "time.HH.MM.SS", `date.time.tz.orig`,
             "date.time.tz.orig.wc", "station_name.wc", pressure.kPa.wc = "pressure.wc", everything()) %>% 
      select(!c(`date.AAAA-MM-JJ.y`, "time.wc")) # enlever les nombreuses colonnes qui n'ont pas rapport dans ces démarches
    colnames(cal.eccc.data)
    
    # Jutras&Bourgault V2.0, 2024; étape b) Calculer la hauteur d’eau au-dessus de la sonde par la soustraction de la pression atmosphérique, convertie en cm d’eau, à la pression mesurée par la sonde
    # Jutras&Bourgault V2.0, 2024; étape b.i)   La conversion de kPa en cm d’eau est : 1 kPa = 10,1972 cm d’eau 
    cal.eccc.data$pression.eau.kPa = cal.eccc.data$raw.value.kPa_pres.abs - cal.eccc.data$pressure.kPa.wc
    cal.eccc.data$hauteur.eau.cm = cal.eccc.data$pression.eau.kPa * 10.1972 # règle de trois
    cal.eccc.data <- cal.eccc.data %>% select("scan.id", "date.time.UTC.0","raw.value.kPa_pres.abs", pression.eau.kPa, hauteur.eau.cm, everything()) 
    
    # Jutras&Bourgault V2.0, 2024; étape c) Convertir la hauteur d’eau au-dessus de la sonde en profondeur de la nappe phréatique par rapport à la surface du sol
    # Jutras&Bourgault V2.0, 2024; étape c.i)   La profondeur de la nappe phréatique par rapport à la surface du sol = (La distance qui sépare l’intérieur du capuchon au trou situé à la base de la sonde – La longueur du puits d’observation qui dépasse la surface du sol) – La hauteur d’eau au-dessus de la sonde
    str(cal.eccc.data$long.fil.cm) # characters
    str(cal.eccc.data$out.long.tuyau.sol.cm) # characters
    cal.eccc.data$calibrated.value.mm <- (cal.eccc.data$long.fil.cm - cal.eccc.data$out.long.tuyau.sol.cm) - (cal.eccc.data$hauteur.eau.cm*10) # hauteur d'eau en cm -> mm = *10
```

## Visualisation de la variation de la nappe phréatique et du positionnement du puits le long du transect

```{r, message = FALSE, include = FALSE}
setwd("~/Documents/Doctorat/_R.&.Stats_PhD") # fonctions utiles et working directory
# sys.source("general.scripts/fonctions.R") # envir = knitr::knit_global())
# load("~/Documents/Doctorat/_R.&.Stats_PhD/connectivite/data/raw/metadata_all.RDS")

#### bibliotheques a charger (installer avant si pas fait)
if (!require("conflicted")) install.packages("conflicted")
if (!require("dplyr")) install.packages("dplyr") # pour manipulation donnees (pipe, etc)
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("gridExtra")) install.packages("gridExtra") # multiplot()
if (!require("stringr")) install.packages("stringr") # str_to_title
if (!require("grDevices")) install.packages("grDevices") # pdf()

##### importer et préparer donnees dans R
ll.clean <- readRDS("connectivite/data/clean/ll.clean.RDS")
# obtenu via le script "/scripts/data_water.table.all.R"
```

```{r, echo = FALSE}
for (i in 1:length(ll.clean)) {
  paste(i)
  # extraire no de sonde
  texte <- ll.clean[[i]]$metadata[4]
  numbers <- gregexpr("[0-9]+", texte)
  result <- regmatches(texte, numbers)
  (probe.serial.no.i <- as.numeric(unlist(result)))
  
  # extraire nom de transect/puits
  cal.data <- read.csv("connectivite/data/raw/level.logger.calibration.all.csv", sep = ";")
  colnames(cal.data)
  transect.id.i.pre <- cal.data$well.id[cal.data$probe.serial.no == probe.serial.no.i]
  transect.id.i <- unique(transect.id.i.pre[!is.na(transect.id.i.pre)])
  
  # extraire nom de site
  site.name.pre <- sub("SiteName","",ll.clean[[i]]$metadata[1])
  site.name.pre.1 <- gsub(",", "", site.name.pre) # ici ce serait ST-HENRI, ça me gosse
  site.name <- str_to_title(site.name.pre.1)
  
  # créer objet contenant les données
  ll.cal <- ll.clean[[i]]$data # ll.cal ce sont les données calibrées finales, reprise du nom dans le script d'origine "data_water.table.all.R"
  # class(ll.cal); head(ll.cal); str(ll.cal); colnames(ll.cal)
  ll.cal$date.time.tz.orig <- as.POSIXct(ll.cal$date.time.tz.orig, tryFormats = )

  # graphiques de nappe phréatique
  graph.wt <- ll.cal %>% ggplot(mapping = aes(y = calibrated.value.mm/10, x = date.time.tz.orig)) + # doit être en as.POSICct, mais avec la date et l'heure. Repartir de zéro dans le script water.tanle_all??
    geom_line(group = 1) +
    scale_x_datetime(
      date_minor_breaks = "day", date_breaks = "2 weeks", date_labels = "%D:%H") +
    ggtitle(paste0(site.name, ", sonde no ", probe.serial.no.i, " à l'emplacement ", transect.id.i, "\n",
                   "nombre de ligne du fichier : ", nrow(ll.cal))) +
    labs(y = "Hauteur de nappe phréatique (cm)", x = "Date") +
    theme_bw() + theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 45, hjust = 1, vjust = 0.5))
  print(graph.wt) # imprimer dans R
  
  # ATTENTION !! surpasser consciemment dans la boucle
  # ggsave(paste0("connectivite/output/figures/",site.name, "_", probe.serial.no.i, "_", transect.id.i,".pdf"), graph.wt, width = 12, height = 8)
}
```

```{r, include = FALSE}

# Afficher tous les graphiques

# pdf("filename.pdf", width = 8, height = 12) # Open a new pdf file
# n <- length(graph.wt)
# nCol <- floor(sqrt(n))
# do.call("grid.arrange", c(graph.wt, ncol=nCol))
# dev.off() # Close the file


# if(paste0('Elevation_Inkerman_graph', transect[i],'.png') %in% list.files("connectivite/output/figures"))  { # si TRUE = STOP et warning // si FALSE = continuer la boucle (donc rien, donc IF statement)
#   stop("Attention, un fichier du même nom se trouve dans le dossier. En outrepassant cet avertissement, le fichier ancier sera effacé et remplacé.")
# } else { ggplot2::ggsave(paste0('output/figures/Elevation_Inkerman_graph',transect[i],'.png'), graph, width = 4.7, height = 2.4)  }



# # Check if the file does not exist
# file_to_check <- paste0('output/figures/Elevation_Inkerman_graph',transect[i],'.png')
# if(!file.exists(file_to_check)){ # si c'est PAS VRAI (le file n'existe pas, on poursuit) = VRAI, si c'est VRAI = FAUX (else if -> message d'erreur, empêche d'écraser)
#   ggplot2::ggsave(paste0('output/figures/Elevation_Inkerman_graph',transect[i],'.png'), graph, width = 4.7, height = 2.4)
#
#   # otherwise print a message
# }else if(file.exists(file_to_check)){
#
#   stop("The file already exists in the current directory!")
# }
# Choix CONSCIENT d'écraser
# ggplot2::ggsave(paste0('output/figures/Elevation_Inkerman_graph',transect[i],'.png'), graph, width = 4.7, height = 2.4)
```
